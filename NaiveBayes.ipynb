{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The %... is an iPython thing, and is not part of the Python language.\n",
    "# In this case we're just telling the plotting library to draw things on\n",
    "# the notebook, instead of on a separate window.\n",
    "%matplotlib inline\n",
    "# See all the \"as ...\" contructs? They're just aliasing the package names.\n",
    "# That way we can call methods like plt.plot() instead of matplotlib.pyplot.plot().\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##The Vector space model\n",
    "\n",
    "See http://nlp.stanford.edu/IR-book/ from which this text is taken.\n",
    "\n",
    "We denote by $\\bar V(d)$ the vector derived from document d, with one com- ponent in the vector for each dictionary term. The set of documents in a collection then may be viewed as a set of vectors in a vector space, in which there is one axis for each term. This representation loses the relative ordering of the terms in each document. The documents Mary is quicker than John and John is quicker than Mary are identical in such a bag of words representation. the standard way of quantifying the similarity between two documents $d_1$ and $d_2$  is to compute the cosine similarity of their vector representations $\\bar V(d_1)$ and $\\bar V(d_2)$:\n",
    "\n",
    "$$S_{12} = \\frac{\\bar V(d_1) \\cdot \\bar V(d_2)}{|\\bar V(d_1)| \\times |\\bar V(d_2)|}$$\n",
    "\n",
    "![Vector Space Model](vsm.png)\n",
    "\n",
    "The formula can be viewed as the dot product of the normalized versions of the two document vectors. Given a document d (potentially one of the $d_i$ in the collection), consider searching for the documents in the collection most similar to d. Such a search is useful in a system where a user may identify a document and seek others like it – a feature available in the results lists of search engines as a more like this feature.\n",
    "\n",
    "Viewing a collection of N documents as a collection of vectors leads to a TERM-DOCUMENT natural view of a collection as a term-document matrix: this is an M × N matrix whose rows represent the M terms (dimensions) of the N columns, each of which corresponds to a document. As always, the terms being indexed could be stemmed before indexing; for instance, jealous and jealousy would under stemming be considered as a single dimension.\n",
    "\n",
    "![novel terms](terms.png)\n",
    "\n",
    "There is a far more compelling reason to represent documents as vectors: we can also view a query as a vector. Consider the query q = jealous gossip. This query turns into the unit vector $\\bar V(q)$ = (0, 0.707, 0.707) on the three coordinates below. \n",
    "\n",
    "![novel terms](terms2.png)\n",
    "\n",
    "The key idea now: to assign to each document d a score equal to the dot product:\n",
    "\n",
    "$$\\bar V(q) \\cdot \\bar V(d)$$\n",
    "\n",
    "Wuthering Heights is the top-scoring docu- ment for this query with a score of 0.509, with Pride and Prejudice a distant second with a score of 0.085, and Sense and Sensibility last with a score of 0.074. This simple example is somewhat misleading: the number of dimensions in practice will be far larger than three: it will equal the vocabulary size M."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Reverend Bayes\n",
    "(From Think Bayes, a very fun Oreilly book(online at http://www.greenteapress.com/thinkbayes/)\n",
    "\n",
    "\n",
    "When two events happen together:\n",
    "\n",
    "$$p(A  and  B) = p(A) p(B|A) $$\n",
    "\n",
    "Flip it:\n",
    "\n",
    "$$p(B  and  A) = p(B) p(A|B) $$\n",
    "\n",
    "Thus\n",
    "\n",
    "$$p(B) p(A|B) = p(A) p(B|A) $$\n",
    "\n",
    "\n",
    "$$p(A|B) = \\frac{p(A) p(B|A)}{p(B)}$$\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Naive Bayes\n",
    "\n",
    "Some parts and code stolen from HW3 for CS109 in 2013. \n",
    "\n",
    "\n",
    "\n",
    "$$P(c|d) \\propto P(d|c) P(c) $$\n",
    "\n",
    "$$P(d|c)  = \\prod_k P(t_k | c) $$, the conditional independence assumption.\n",
    "\n",
    "Then we see that for which c is $P(c|d)$ higher.\n",
    "\n",
    "For floating point underflow we change the product into a sum. But we must also handle non-existent terms, we cant have 0's for them:\n",
    "\n",
    "$$P(t_k|c) = \\frac{N_{kc}+\\alpha}{N_c+\\alpha N_{feat}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Rotten tomatoes data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh    imdb     publication                                              quote review_date  rtid      title\n",
       "1         Derek Adams  fresh  114709        Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story\n",
       "2     Richard Corliss  fresh  114709   TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story\n",
       "3         David Ansen  fresh  114709        Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story\n",
       "4       Leonard Klady  fresh  114709         Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story\n",
       "5  Jonathan Rosenbaum  fresh  114709  Chicago Reader  An entertaining computer-generated, hyperreali...  2008-03-10  9559  Toy story"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critics = pd.read_csv('./critics.csv')\n",
    "#let's drop rows with missing quotes\n",
    "critics = critics[~critics.quote.isnull()]\n",
    "critics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 15561\n",
      "Number of critics: 623\n",
      "Number of movies:  1921\n"
     ]
    }
   ],
   "source": [
    "n_reviews = len(critics)\n",
    "n_movies = critics.rtid.unique().size\n",
    "n_critics = critics.critic.unique().size\n",
    "\n",
    "\n",
    "print \"Number of reviews: %i\" % n_reviews\n",
    "print \"Number of critics: %i\" % n_critics\n",
    "print \"Number of movies:  %i\" % n_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x10add7cd0>,\n",
       "  <matplotlib.axis.YTick at 0x10add7510>,\n",
       "  <matplotlib.axis.YTick at 0x10a1ce610>,\n",
       "  <matplotlib.axis.YTick at 0x10a20bf10>,\n",
       "  <matplotlib.axis.YTick at 0x10a21e6d0>,\n",
       "  <matplotlib.axis.YTick at 0x10a21ee50>],\n",
       " <a list of 6 Text yticklabel objects>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxQAAAIqCAYAAAC9hAz4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10add1b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = critics.copy()\n",
    "df['fresh'] = df.fresh == 'fresh'\n",
    "grp = df.groupby('critic')\n",
    "counts = grp.critic.count()  # number of reviews by each critic\n",
    "means = grp.fresh.mean()     # average freshness for each critic\n",
    "\n",
    "means[counts > 100].hist(bins=10, edgecolor='w', lw=1)\n",
    "plt.xlabel(\"Average rating per critic\")\n",
    "plt.ylabel(\"N\")\n",
    "plt.yticks([0, 2, 4, 6, 8, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text is\n",
      "Hop on pop\n",
      "Hop off pop\n",
      "Hop Hop hop\n",
      "\n",
      "Transformed text vector is \n",
      "[[1 0 1 1]\n",
      " [1 1 0 1]\n",
      " [3 0 0 0]]\n",
      "\n",
      "Words for each feature:\n",
      "[u'hop', u'off', u'on', u'pop']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = ['Hop on pop', 'Hop off pop', 'Hop Hop hop']\n",
    "print \"Original text is\\n\", '\\n'.join(text)\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0)\n",
    "\n",
    "# call `fit` to build the vocabulary\n",
    "vectorizer.fit(text)\n",
    "\n",
    "# call `transform` to convert text to a bag of words\n",
    "x = vectorizer.transform(text)\n",
    "\n",
    "# CountVectorizer uses a sparse array to save memory, but it's easier in this assignment to \n",
    "# convert back to a \"normal\" numpy array\n",
    "x = x.toarray()\n",
    "\n",
    "print\n",
    "print \"Transformed text vector is \\n\", x\n",
    "\n",
    "# `get_feature_names` tracks which word is associated with each column of the transformed x\n",
    "print\n",
    "print \"Words for each feature:\"\n",
    "print vectorizer.get_feature_names()\n",
    "\n",
    "# Notice that the bag of words treatment doesn't preserve information about the *order* of words, \n",
    "# just their frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_xy(critics, vectorizer=None):\n",
    "    #Your code here    \n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(critics.quote)\n",
    "    X = X.tocsc()  # some versions of sklearn return COO format\n",
    "    y = (critics.fresh == 'fresh').values.astype(np.int)\n",
    "    return X, y\n",
    "X, y = make_xy(critics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MN Accuracy: 76.90%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y)\n",
    "clf = MultinomialNB().fit(xtrain, ytrain)\n",
    "print \"MN Accuracy: %0.2f%%\" % (100 * clf.score(xtest, ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.92\n",
      "Accuracy on test data:     0.77\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "print \"Accuracy on test data:     %0.2f\" % (test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Cross-Validation and hyper-parameter fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765118166871\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "result = 0\n",
    "nfold = 5\n",
    "for train, test in KFold(y.size, nfold): # split data into train/test groups, 5 times\n",
    "    clf.fit(X[train], y[train]) # fit\n",
    "    result += clf.score(X[test], y[test]) # evaluate score function on held-out data\n",
    "print result / nfold # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cv_score(clf, X, y, scorefunc):\n",
    "    result = 0.\n",
    "    nfold = 5\n",
    "    for train, test in KFold(y.size, nfold): # split data into train/test groups, 5 times\n",
    "        clf.fit(X[train], y[train]) # fit\n",
    "        result += scorefunc(clf, X[test], y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the log-likelyhood as the score here. We'll go into this later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_likelihood(clf, x, y):\n",
    "    prob = clf.predict_log_proba(x)\n",
    "    rotten = y == 0\n",
    "    fresh = ~rotten\n",
    "    return prob[rotten, 0].sum() + prob[fresh, 1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the grid of parameters to search over\n",
    "alphas = [0, .1, 1, 5, 10, 50]\n",
    "min_dfs = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "\n",
    "#Find the best value for alpha and min_df, and the best classifier\n",
    "best_alpha = None\n",
    "best_min_df = None\n",
    "maxscore=-np.inf\n",
    "for alpha in alphas:\n",
    "    for min_df in min_dfs:         \n",
    "        vectorizer = CountVectorizer(min_df = min_df)       \n",
    "        Xthis, ythis = make_xy(critics, vectorizer)\n",
    "        \n",
    "        #your code here\n",
    "        clf = MultinomialNB(alpha=alpha)\n",
    "        cvscore = cv_score(clf, Xthis, ythis, log_likelihood)\n",
    "\n",
    "        if cvscore > maxscore:\n",
    "            maxscore = cvscore\n",
    "            best_alpha, best_min_df = alpha, min_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 5.000000\n",
      "min_df: 0.001000\n"
     ]
    }
   ],
   "source": [
    "print \"alpha: %f\" % best_alpha\n",
    "print \"min_df: %f\" % best_min_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Work with the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.79\n",
      "Accuracy on test data:     0.74\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=best_min_df)\n",
    "X, Y = make_xy(critics, vectorizer)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y)\n",
    "\n",
    "clf = MultinomialNB(alpha=best_alpha).fit(xtrain, ytrain)\n",
    "\n",
    "# Your code here. Print the accuracy on the test and training dataset\n",
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "print \"Accuracy on test data:     %0.2f\" % (test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 950  570]\n",
      " [ 444 1927]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print confusion_matrix(ytest, clf.predict(xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good words\t     P(fresh | word)\n",
      "             delight 0.90\n",
      "         masterpiece 0.89\n",
      "         intelligent 0.88\n",
      "           hilarious 0.88\n",
      "             kubrick 0.87\n",
      "               witty 0.87\n",
      "            touching 0.87\n",
      "          remarkable 0.86\n",
      "         beautifully 0.86\n",
      "               smart 0.86\n",
      "Bad words\t     P(fresh | word)\n",
      "               sadly 0.21\n",
      "            tiresome 0.19\n",
      "               bland 0.18\n",
      "                dull 0.18\n",
      "             unfunny 0.18\n",
      "          uninspired 0.18\n",
      "      disappointment 0.17\n",
      "           pointless 0.16\n",
      "                lame 0.15\n",
      "       unfortunately 0.14\n"
     ]
    }
   ],
   "source": [
    "words = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "x = np.eye(xtest.shape[1])\n",
    "probs = clf.predict_log_proba(x)[:, 0]\n",
    "ind = np.argsort(probs)\n",
    "\n",
    "good_words = words[ind[:10]]\n",
    "bad_words = words[ind[-10:]]\n",
    "\n",
    "good_prob = probs[ind[:10]]\n",
    "bad_prob = probs[ind[-10:]]\n",
    "\n",
    "print \"Good words\\t     P(fresh | word)\"\n",
    "for w, p in zip(good_words, good_prob):\n",
    "    print \"%20s\" % w, \"%0.2f\" % (1 - np.exp(p))\n",
    "    \n",
    "print \"Bad words\\t     P(fresh | word)\"\n",
    "for w, p in zip(bad_words, bad_prob):\n",
    "    print \"%20s\" % w, \"%0.2f\" % (1 - np.exp(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mis-predicted Rotten quotes\n",
      "---------------------------\n",
      "Herzog offers some evidence of Kinski's great human warmth, somewhat more of his rage of unimaginable proportions, and a good demonstration of Kinski's uncanny capacity to corkscrew his way into the frame.\n",
      "\n",
      "Benefits from a lively lead performance by the miscast Denzel Washington but doesn't come within light years of the book, one of the greatest American autobiographies.\n",
      "\n",
      "It's a sad day when an actor who's totally, beautifully in touch with his dark side finds himself stuck in a movie that's scared of its own shadow.\n",
      "\n",
      "The Waterboy is arguably Sandler's most enjoyable motion picture to date, but it's still far from a masterpiece.\n",
      "\n",
      "It is sometimes funny in a puzzling kind of way, it is generally overwrought in an irritating kind of way, and once in a while it is inappropriately touching.\n",
      "\n",
      "Mis-predicted Fresh quotes\n",
      "--------------------------\n",
      "The gangland plot is flimsy (bad guy Peter Greene wears too much eyeliner), and the jokes are erratic, but it's a far better showcase for Carrey's comic-from-Uranus talent than Ace Ventura.\n",
      "\n",
      "A good half-hour's worth of nonsense in the middle keeps Bad Boys from being little better than a break- even proposition.\n",
      "\n",
      "There's too much talent and too strong a story to mess it up. There was potential for more here, but this incarnation is nothing to be ashamed of, and some of the actors answer the bell.\n",
      "\n",
      "Some of the gags don't work, but fewer than in any previous Brooks film that I've seen, and when the jokes are meant to be bad, they are riotously poor. What more can one ask of Mel Brooks?\n",
      "\n",
      "Though it's a good half hour too long, this overblown 1993 spin-off of the 60s TV show otherwise adds up to a pretty good suspense thriller.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, y = make_xy(critics, vectorizer)\n",
    "\n",
    "prob = clf.predict_proba(x)[:, 0]\n",
    "predict = clf.predict(x)\n",
    "\n",
    "bad_rotten = np.argsort(prob[y == 0])[:5]\n",
    "bad_fresh = np.argsort(prob[y == 1])[-5:]\n",
    "\n",
    "print \"Mis-predicted Rotten quotes\"\n",
    "print '---------------------------'\n",
    "for row in bad_rotten:\n",
    "    print critics[y == 0].quote.irow(row)\n",
    "    print\n",
    "\n",
    "print \"Mis-predicted Fresh quotes\"\n",
    "print '--------------------------'\n",
    "for row in bad_fresh:\n",
    "    print critics[y == 1].quote.irow(row)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01834196,  0.98165804]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(vectorizer.transform(['This movie is not remarkable, touching, or superb in any way']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
